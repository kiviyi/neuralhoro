{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "\n",
    "# –î–ª—è –±–æ–ª—å—à–µ–π –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π GPT –æ—Ç –°–±–µ—Ä–∞.\n",
    "# –ù–∏–∂–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33169854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus rog\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "text = open(r'C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\data.txt', encoding='utf-8').read()\n",
    "# –°–æ—Ö—Ä–∞–Ω–∏–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ .txt —Ñ–∞–π–ª \n",
    "train_path = r\"C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\data.txt\"\n",
    "# with open(train_path, \"w\") as f:\n",
    "#     f.write(text)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "train_dataset = TextDataset(tokenizer=tokenizer,file_path=train_path,block_size=64)\n",
    "print(len(text))\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞–ª–æ–¥–µ—Ä–∞ (–Ω–∞—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ –¥–ª–∏–Ω–µ –∫—É—Å–∫–∏)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=200, # number of training epochs\n",
    "    per_device_train_batch_size=16, # batch size for training\n",
    "    per_device_eval_batch_size=16,  # batch size for evaluation\n",
    "    warmup_steps=10,# number of warmup steps for learning rate scheduler\n",
    "    gradient_accumulation_steps=16, # to make \"virtual\" batch size larger\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10083\n",
      "  Num Epochs = 200\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 7800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7800' max='7800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7800/7800 6:02:50, Epoch 199/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.816700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.682100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.636100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.623700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./finetuned\\checkpoint-500\n",
      "Configuration saved in ./finetuned\\checkpoint-500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-1000\n",
      "Configuration saved in ./finetuned\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-1500\n",
      "Configuration saved in ./finetuned\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-2000\n",
      "Configuration saved in ./finetuned\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-2000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-2500\n",
      "Configuration saved in ./finetuned\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-2500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-3000\n",
      "Configuration saved in ./finetuned\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-3000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-3500\n",
      "Configuration saved in ./finetuned\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-4000\n",
      "Configuration saved in ./finetuned\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-4000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-4500\n",
      "Configuration saved in ./finetuned\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-4500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-5000\n",
      "Configuration saved in ./finetuned\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-5000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-5500\n",
      "Configuration saved in ./finetuned\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-6000\n",
      "Configuration saved in ./finetuned\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-6000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-6500\n",
      "Configuration saved in ./finetuned\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-6500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-7000\n",
      "Configuration saved in ./finetuned\\checkpoint-7000\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-7000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./finetuned\\checkpoint-7500\n",
      "Configuration saved in ./finetuned\\checkpoint-7500\\config.json\n",
      "Model weights saved in ./finetuned\\checkpoint-7500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7800, training_loss=2.002399127666767, metrics={'train_runtime': 21775.6177, 'train_samples_per_second': 92.608, 'train_steps_per_second': 0.358, 'total_flos': 6.5861955477504e+16, 'train_loss': 2.002399127666767, 'epoch': 199.99})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model\n",
      "Configuration saved in C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33169854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "print(len(text))\n",
    "trainer.save_model(r'C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading file vocab.json from cache at C:\\Users\\asus rog/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\f2f7c585b05a16726efe8974586e10b4d5939082\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\asus rog/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\f2f7c585b05a16726efe8974586e10b4d5939082\\merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\asus rog/.cache\\huggingface\\hub\\models--sberbank-ai--rugpt3small_based_on_gpt2\\snapshots\\f2f7c585b05a16726efe8974586e10b4d5939082\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"sberbank-ai/rugpt3small_based_on_gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 2048,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 2048,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "model_name_or_path = r'C:\\Users\\asus rog\\Documents\\parsinghoroscop\\rnn\\model'\n",
    "\n",
    "model  = GPT2LMHeadModel.from_pretrained(model_name_or_path).to(DEVICE)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "\n",
    "trainer = Trainer(model = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–°—Ç—Ä–µ–ª—å—Ü—ã,  —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ü–µ–ª–∏ –∏ –∞–º–±–∏—Ü–∏–∏, –º–æ–≥—É—Ç –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞ –≤ —á–µ–º-—Ç–æ –±—ã—Å—Ç—Ä–æ –∏ –ª–µ–≥–∫–æ. –ì–ª–∞–≤–Ω–æ–µ ‚Äì –Ω–µ –±–æ—è—Ç—å—Å—è —Ä–∏—Å–∫–æ–≤–∞—Ç—å –∏ —Å–æ–≥–ª–∞—à–∞—Ç—å—Å—è –Ω–∞ –∞–≤–∞–Ω—Ç—é—Ä—ã. –í –æ—Ç–Ω–æ—à–µ–Ω–∏—è—Ö —Å–µ–π—á–∞—Å —Ü–∞—Ä–∏—Ç –º–∏—Ä, —Ä–∞–¥–æ—Å—Ç—å, –ª—é–±–æ–≤—å –∏ –≤–∑–∞–∏–º–æ–ø–æ–Ω–∏–º–∞–Ω–∏–µ. –ü–æ—Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å –Ω–µ —Å–ø–æ—Ä–∏—Ç—å –∏ –Ω–µ —Å—Å–æ—Ä–∏—Ç—å—Å—è ‚Äì —ç—Ç–æ –ª–∏—à—å –∏—Å–ø–æ—Ä—Ç–∏—Ç –≤–∞—à–∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è.\n",
      "–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ —Å–µ–≥–æ–¥–Ω—è –≤—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–æ–∑–∏—Ç–∏–≤–Ω–æ, –¥–µ–Ω—å –Ω–µ —Å—É–ª–∏—Ç –≤–∞–º —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º, –ø–æ—ç—Ç–æ–º—É —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ —Ä–∞–±–æ—á–∏—Ö –¥–µ–ª–∞—Ö. –¢–∞–∫–∂–µ –∑–≤–µ–∑–¥—ã —Å–æ–≤–µ—Ç—É—é—Ç –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫–æ–ª–ª–µ–≥–∞–º ‚Äì —Ç–∞–∫ —É –≤–∞—Å –ø–æ–ª—É—á–∏—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ –∑–∞–∫–æ–Ω—á–∏—Ç—å –≤—Å–µ –¥–µ–ª–∞. –ù–µ –±–æ–π—Ç–µ—Å—å –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ –±–ª–∏–∑–∫–∏–º ‚Äì –æ–Ω–∏ —Ç–æ—á–Ω–æ —Å–ø—Ä–∞–≤—è—Ç—Å—è —Å –Ω–∏–º–∏. –¢–∞–∫–∂–µ —Å–µ–≥–æ–¥–Ω—è –Ω–µ —Å—Ç–æ–∏—Ç –≤–≤—è–∑—ã–≤–∞—Ç—å—Å—è –≤ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏ —Å–ø–æ—Ä–∏—Ç—å ‚Äì –≤—ã –Ω–µ –≤—ã–∏–≥—Ä–∞–µ—Ç–µ –Ω–∏ –≤ –æ–¥–Ω–æ–π –∏–≥—Ä–µ. –ü–æ–ª–µ–∑–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ø–æ—Ç–µ –ª–∏—Ü–∞ ‚Äì –∑–≤–µ–∑–¥—ã –≥–æ–≤–æ—Ä—è—Ç, —á—Ç–æ –≤—ã —Å–º–æ–∂–µ—Ç–µ –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞ –≤–æ –≤—Å–µ–º. –¢–∞–∫–∂–µ –ø–æ–ª–µ–∑–Ω–æ –ø–æ–º–æ–≥–∞—Ç—å –Ω—É–∂–¥–∞—é—â–∏–º—Å—è ‚Äì —ç—Ç–æ –ø–æ–¥–Ω–∏–º–µ—Ç –≤–∞–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ. –ê –≤–æ—Ç –Ω–∞ –ª–∏—á–Ω–æ–º —Ñ—Ä–æ–Ω—Ç–µ –≤—Å–µ –Ω–µ —Ç–∞–∫ —Ä–∞–¥—É–∂–Ω–æ ‚Äì –≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∏—Ä–≤–æ–∞–Ω–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º\n",
    "text = \"–°—Ç—Ä–µ–ª—å—Ü—ã, \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        num_beams=2,\n",
    "                        temperature=1.5,\n",
    "                        top_p=0.9,\n",
    "                        max_length=200,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
